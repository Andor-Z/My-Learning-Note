{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch02 K-Nearest Neighbor (KNN,K-邻近算法)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 k-NN算法\n",
    "- **工作原理**  \n",
    "存在一个样本数据集合，我们有这个training set 每条数据的label(标签). We know what class each piece of the data should fall into(我们知道样本数据中每一数据与所属分类的对应关系).When we're given a new piece of data without a label, we compare that new piece of data to exiting data, every piece of existing data. Then we take the most similar piece of data(the nearest neighbor) and look at their labels. We look at the top k most similar pieces of data from our known data set; this is where the *k*  comes from. ( *k* is an integer and it's usually than 20.) Lasty, we take a majority vote from the K most similar pieces of data, and the majority is the new class we assign to the data we were asked to classify(分类).  \n",
    "- **Geenral approach to kNN**  \n",
    "    1. Collect data\n",
    "    2. Prepare data\n",
    "    3. Analyze \n",
    "    4.Train\n",
    "    5. Test\n",
    "    6. Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### k-Nearest Neighbors algorithm function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "\n",
    "def creatDataSet():\n",
    "    group = np.array([[1.0, 1.1], [1.0, 1.0], [0, 0], [0, 0.1]])\n",
    "    labels = ['A','A', 'B', 'B']\n",
    "    return group, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `classify0()`函数详解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify0(inX, dataSet, labels, k):\n",
    "    dataSetSize = dataSet.shape[0]\n",
    "    # training example called dataSet\n",
    "    diffMat = np.tile(inX, (dataSetSize, 1)) - dataSet\n",
    "    # X是a*b的矩阵，np.tile（X, (m, n))  是将X复制为a*m行，b*n列的矩阵\n",
    "    sqDiffMat = diffMat ** 2\n",
    "    sqDistance = sqDiffMat.sum(axis = 1)\n",
    "    # array.sum(axis=1)按行累加，axis=0为按列累加\n",
    "    distance = sqDistance ** 0.5\n",
    "    sortedDistIndicies = distance.argsort()\n",
    "    # argsort()是numpy中的方法，得到矩阵中每个元素的排序序号\n",
    "    # A=array.argsort()  A[0]表示排序后 排在第一个的那个数在原来数组中的下标\n",
    "    classCount = {} \n",
    "    for i in range(k):\n",
    "        voteIlabel = labels[sortedDistIndicies[i]]\n",
    "        classCount[voteIlabel] = classCount.get(voteIlabel, 0) + 1 \n",
    "    sortedClassCount = sorted(classCount.iteritems(), key = operator.itemgetter(1), reverse = True)\n",
    "    return sortedClassCount[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`classify0()`函数是一个分类器 classifier，使用了欧氏距离公式(Euclidian distance)计算向量之间的距离。\n",
    "而Euclidian distance 是闵可夫斯基距离(Minkowski distance)参数r为2时的具体体现。  \n",
    "首先需要明确一点，传入参数 inX，并不是多维向量，只是单个的输入向量，和dataSet(training example)中的一行相当。这样就容易理解后面的`numpy.tile`函数了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `numpy.tile`函数\n",
    "```\n",
    "dataSetSize = dataSet.shape[0]\n",
    "diffMat = np.tile(inX, (dataSetSize, 1)) - dataSet\n",
    "```\n",
    "dataSet 是(m,n)维向量，同时必须得是用numpy.array()函数构造的  \n",
    "m 是行数，也是training example 的数据量  \n",
    "n 是列数，也是特征值  \n",
    "dataSetSize 是 dataSet 的行数\n",
    "inX 是(1, n)维向量，也就是单个输入向量\n",
    "np.tile(inX, (dataSetSize, 1)) 是将(1, n)维的向量，copy成(dataSetSize\\*1, 1\\*n)维向量  \n",
    "这样就和 dataSet 同一维度了，就可以相减了   \n",
    "  \n",
    "  \n",
    "事实上，np.tile函数要复杂的多  \n",
    "参考：  \n",
    "[Numpy的tile函数--沫沫的博客](http://blog.sina.com.cn/s/blog_6bd0612b0101cr3u.html)  \n",
    "[numpy.tile官方文档](http://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html)\n",
    "tile(A, reps)  \n",
    "假设 A 的**维度**是d，reps 的**长度**是len  \n",
    "当d > len 时，将reps长度补足为d， 即在reps前面加上d-len个1。  \n",
    "reps = (n1, n2, n3,..., nlen)\n",
    "new_reps = (1, 1, ..d-len个1,1, n1, n2, n3,..., nlen)\n",
    "new_A = tile(A, reps)  \n",
    "将tile过程理解为一个复制copy的过程  \n",
    "首先将A中最低的维度--**行**copy nlen 次为新行  \n",
    "然后以二维为单位 copy n(len-1) 次  \n",
    "然后一直这样从低维向高维操作  \n",
    "##### `array.sum()`  \n",
    "array.sum(axis=1)按行累加，axis=0为按列累加  \n",
    "##### `argsort()`  \n",
    "A=array.argsort()  A[0]表示排序后 排在第一个的那个数在原来数组中的下标\n",
    "##### `iteritems()`\n",
    "迭代输出字典的键值  \n",
    "```\n",
    "for k,v in dict.iteritems():\n",
    "    print k,v\n",
    "```\n",
    "比items工作效率高\n",
    "**!!!!**Python3 列表中直接用items()取代了iteritems(), 也就是说Python3中dict.items() 返回的也是iterator。\n",
    "##### `sorted()`\n",
    "参考：  \n",
    "[sorted--廖雪峰](http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/0014318230588782cac105d0d8a40c6b450a232748dc854000)  \n",
    "[Python中的sorted函数以及operator.itemgetter函数--Mountain](http://www.cnblogs.com/100thMountain/p/4719503.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "后面没什么特别难的，待整理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然现在已经构造了一个k-NN分类器，但这并不是机器学习，起码不是完整的机器学习。  \n",
    "《统计学习方法》一书中写到：统计学习方法由 **模型、策略、算法** 三要素构成。  \n",
    "**模型**的假设空间 (hypothesis space) ， 我目前粗浅的理解为，算法以及函数的集合，如本例中的k-NN算法，以及其中的欧几里得距离。  \n",
    "本例中的算法，一、可以采取其他计算距离的公式，如闵可夫斯基公式的其他参数；二、可以采用除k-NN的其他算法。这些所有的可能算法都应被包含在模型的hypothesis space 中。  \n",
    "而策略则是如何从模型的 hypothesis space 中取得最优模型。  \n",
    "所以说，一个较为完整的机器学习，应该是根据**策略**，从**hypothesis space** 中选取最优模型，同时选取计算最优模型的算法。  \n",
    "本例只是做了其中算法的一个小部分。  \n",
    "以上皆为初学者浅显的理解。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
